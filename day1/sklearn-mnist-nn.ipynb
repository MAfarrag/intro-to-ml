{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST handwritten digits classification with nearest neighbors \n",
    "\n",
    "In this notebook, we'll use [nearest-neighbor classifiers](http://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification) to classify MNIST digits using scikit-learn (version 0.20 or later required).\n",
    "\n",
    "First, the needed imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors, datasets, __version__\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from distutils.version import LooseVersion as LV\n",
    "assert(LV(__version__) >= LV(\"0.20\")), \"Version >= 0.20 of sklearn is required.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the MNIST data. First time we need to download the data, which can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.fetch_openml('mnist_784')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    mnist['data'], mnist['target'], test_size=10000, shuffle=True)\n",
    "     \n",
    "print()\n",
    "print('MNIST data loaded: train:',len(X_train),'test:',len(X_test))\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data (`X_train`) is a matrix of size (60000, 784), i.e. it consists of 60000 digits expressed as 784 sized vectors (28x28 images flattened to 1D). `y_train` is a 60000-dimensional vector containing the correct classes (\"0\", \"1\", ..., \"9\") for each training digit.\n",
    "\n",
    "Let's take a closer look. Here are the first 10 training digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i,:].reshape(28, 28), cmap=\"gray\")\n",
    "    plt.title('Class: '+y_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN (k-nearest neighbors) classifier\n",
    "\n",
    "![title](imgs/500px-KnnClassification.svg.png)\n",
    "\n",
    "<br/>\n",
    "\n",
    "<center><small>Image by Antti Ajanki AnAj (Own work) [<a href=\"http://www.gnu.org/copyleft/fdl.html\">GFDL</a>, <a href=\"http://creativecommons.org/licenses/by-sa/3.0/\">CC-BY-SA-3.0</a> or <a href=\"http://creativecommons.org/licenses/by-sa/2.5-2.0-1.0\">CC BY-SA 2.5-2.0-1.0</a>], <a href=\"https://commons.wikimedia.org/wiki/File%3AKnnClassification.svg\">via Wikimedia Commons</a></small></center>\n",
    "\n",
    "\n",
    "## 1-NN classifier\n",
    "\n",
    "### Initialization\n",
    "\n",
    "Let's create first a 1-NN classifier.  Note that with nearest-neighbor classifiers there is no internal (parameterized) model and therefore no learning required.  Instead, calling the `fit()` function simply stores the samples of the training data in a suitable data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_neighbors = 1\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "And try to classify some test samples with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictions = clf.predict(X_test[:200,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the classifier is rather slow, and classifying the whole test set would take quite some time. What is the reason for this?\n",
    "\n",
    "The accuracy of the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Predicted', len(predictions), 'digits with accuracy:', accuracy_score(y_test[:len(predictions)], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster 1-NN classifier\n",
    "\n",
    "### Initialization\n",
    "\n",
    "One way to make our 1-NN classifier faster is to use less training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_neighbors = 1\n",
    "n_data = 1024\n",
    "clf_reduced = neighbors.KNeighborsClassifier(n_neighbors)\n",
    "clf_reduced.fit(X_train[:n_data,:], y_train[:n_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Now we can use the classifier created with reduced data to classify our whole test set in a reasonable amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictions_reduced = clf_reduced.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification accuracy is however now not as good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Predicted', len(predictions_reduced), 'digits with accuracy:', accuracy_score(y_test, predictions_reduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect the results in more detail. Let's define and use a helper function to show the wrongly classified test digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_failures(predictions, trueclass=None, predictedclass=None, maxtoshow=10):\n",
    "    errors = predictions!=y_test\n",
    "    print('Showing max', maxtoshow, 'first failures. '\n",
    "          'The predicted class is shown first and the correct class in parenthesis.')\n",
    "    ii = 0\n",
    "    plt.figure(figsize=(maxtoshow, 1))\n",
    "    for i in range(X_test.shape[0]):\n",
    "        if ii>=maxtoshow:\n",
    "            break\n",
    "        if errors[i]:\n",
    "            if trueclass is not None and y_test[i] != trueclass:\n",
    "                continue\n",
    "            if predictedclass is not None and predictions[i] != predictedclass:\n",
    "                continue\n",
    "            plt.subplot(1, maxtoshow, ii+1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(X_test[i,:].reshape(28, 28), cmap=\"gray\")\n",
    "            plt.title(\"%s (%s)\" % (predictions[i], y_test[i]))\n",
    "            ii = ii + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_failures(predictions_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the classifier makes rather \"easy\" mistakes, and there might be room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tuning\n",
    "\n",
    "Try to improve the accuracy of the nearest-neighbor classifier while preserving a reasonable runtime to classify the whole test set. Things to try include using more than one neighbor (with or without weights) or increasing the amount of training data.  See the documentation for [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn-neighbors-kneighborsclassifier).\n",
    "\n",
    "See also http://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
