{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST handwritten digits clustering and anomaly detection\n",
    "\n",
    "In this notebook, we'll use unsupervised learning (clustering and anomaly detection) to analyze MNIST digits using scikit-learn.\n",
    "\n",
    "First, the needed imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from pml_utils import get_mnist, show_clusters, show_anomalies\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import __version__\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from distutils.version import LooseVersion as LV\n",
    "assert(LV(__version__) >= LV(\"0.20\")), \"Version >= 0.20 of sklearn is required.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the MNIST data. First time it downloads the data, which can take a while.\n",
    "\n",
    "To speed up the computations, let's use only 10000 digits in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = get_mnist('../MNIST')\n",
    "\n",
    "X = X_train[:10000]\n",
    "y = y_train[:10000]\n",
    "print()\n",
    "print('MNIST data loaded:')\n",
    "print('X:', X.shape)\n",
    "print('y:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "### k-means\n",
    "\n",
    "K-means clusters data by trying to separate samples in *k* groups of equal variance using an iterative two-step algorithm. It requires the number of clusters as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_clusters_kmeans = 10\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters_kmeans)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sizes of the clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(kmeans.labels_, bins=range(kmeans.n_clusters+1),\n",
    "         rwidth=0.5)\n",
    "plt.xticks(0.5+np.arange(kmeans.n_clusters),\n",
    "           np.arange(kmeans.n_clusters))\n",
    "plt.title('Cluster sizes');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-means centroids are vectors in the same space as the original data, so we can take a look at them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(kmeans.n_clusters, 1))\n",
    "\n",
    "for i in range(kmeans.n_clusters):\n",
    "    plt.subplot(1, kmeans.n_clusters, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(kmeans.cluster_centers_[i,:].reshape(28,28), cmap=\"gray\")\n",
    "    plt.title(str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also draw some digits from each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_clusters(kmeans.labels_, kmeans.n_clusters, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "Since we know the correct labels for MNIST digits, we can evaluate the quality of the clustering. We'll use the [adjusted Rand index](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html) which considers all pairs of samples and counts pairs that are assigned in the same or different clusters in the predicted and true clusterings. The index is between 0.0 and 1.0 with higher values denoting better clusterings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adjusted Rand index: %.3f\"\n",
    "      % adjusted_rand_score(y, kmeans.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical clustering\n",
    "\n",
    "Hierarchical clustering is a family of clustering algorithms that build nested clusters by merging or splitting them successively.\n",
    "\n",
    "The `linkage` criteria determines the metric used for the merge strategy:\n",
    "* `ward` minimizes the sum of squared differences within all clusters\n",
    "* `complete` linkage minimizes the maximum distance between observations of pairs of clusters\n",
    "* `average` linkage minimizes the average of the distances between all observations of pairs of clusters\n",
    "* `single` linkage minimizes the distance between the closest observations of pairs of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_clusters_hclust = 10\n",
    "linkage_hclust = \"ward\"\n",
    "\n",
    "hclust = AgglomerativeClustering(n_clusters=n_clusters_hclust,\n",
    "                                 linkage=linkage_hclust)\n",
    "hclust.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sizes of the clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hclust.labels_, bins=range(hclust.n_clusters+1),\n",
    "         rwidth=0.5)\n",
    "plt.xticks(0.5+np.arange(hclust.n_clusters),\n",
    "           np.arange(hclust.n_clusters))\n",
    "plt.title('Cluster sizes');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some digits from each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_clusters(hclust.labels_, hclust.n_clusters, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adjusted Rand index: %.3f\"\n",
    "      % adjusted_rand_score(y, hclust.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us begin by creating some outliers in our data. We \n",
    "* invert all pixels of one sample\n",
    "* shuffle all pixels of one sample, and\n",
    "* add salt-and-pepper noise to 10% of pixels of one sample.\n",
    "\n",
    "You can also try creating more outliers in a similar fashion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[9999,:]=255-X[9999,:]\n",
    "np.random.shuffle(X[9998,:])\n",
    "for i in np.random.randint(0, X.shape[1], int(X.shape[1]*0.1)):\n",
    "    X[9997,i] = 0.0 if np.random.rand()<0.5 else 255.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at our outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_outliers = 3\n",
    "\n",
    "pltsize = 5\n",
    "plt.figure(figsize=(n_outliers*pltsize, pltsize))\n",
    "\n",
    "for i in range(n_outliers):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X[9999-i,:].reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if_contamination = 0.001\n",
    "\n",
    "if_model = IsolationForest(contamination=if_contamination, behaviour='new')\n",
    "if_pred = if_model.fit(X).predict(X)\n",
    "print('Number of anomalies:', np.sum(if_pred==-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_anomalies(if_pred, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local outlier factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lof_contamination = 0.001\n",
    "\n",
    "lof_model = LocalOutlierFactor(contamination=lof_contamination)\n",
    "lof_pred = lof_model.fit_predict(X)\n",
    "print('Number of anomalies:', np.sum(lof_pred==-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_anomalies(lof_pred, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
